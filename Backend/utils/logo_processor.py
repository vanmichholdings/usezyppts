# =====================
# Imports
# =====================
import os
import tempfile
import logging
import shutil
import time
import numpy as np
from PIL import Image, ImageDraw, ImageFilter, ImageOps, ImageFont
from lxml import etree
import cairosvg
from typing import Dict, Optional, Callable, Any, List, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import queue
import xml.etree.ElementTree as ET
import pickle
import hashlib

# PDF and SVG processing imports
try:
    from pdf2image import convert_from_path
    PDF2IMAGE_AVAILABLE = True
except ImportError as e:
    print(f"Warning: pdf2image import failed: {e}")
    PDF2IMAGE_AVAILABLE = False
except Exception as e:
    print(f"Warning: pdf2image import error: {e}")
    PDF2IMAGE_AVAILABLE = False

try:
    import cairosvg
    CAIROSVG_AVAILABLE = True
except ImportError as e:
    print(f"Warning: cairosvg import failed: {e}")
    CAIROSVG_AVAILABLE = False
except Exception as e:
    print(f"Warning: cairosvg import error: {e}")
    CAIROSVG_AVAILABLE = False

try:
    import cv2
    CV2_AVAILABLE = True
except ImportError as e:
    print(f"Warning: OpenCV import failed: {e}")
    CV2_AVAILABLE = False
except Exception as e:
    print(f"Warning: OpenCV import error: {e}")
    CV2_AVAILABLE = False


# Optional/advanced imports
try:
    from sklearn.cluster import KMeans
except ImportError:
    KMeans = None

try:
    import torch
except ImportError:
    torch = None

try:
    import vtracer  # type: ignore
    VTRACER_AVAILABLE = True
except ImportError as e:
    print(f"Warning: vtracer import failed: {e}")
    VTRACER_AVAILABLE = False
except Exception as e:
    print(f"Warning: vtracer import error: {e}")
    VTRACER_AVAILABLE = False

# =====================
# Constants & Utilities
# =====================
SUPPORTED_FORMATS = ['.png', '.jpg', '.jpeg', '.webp', '.svg']
DEFAULT_SOCIAL_SIZES = {
    'instagram_profile': (180, 180),
    'instagram_post': (1080, 1080),
    'instagram_story': (1080, 1920),
    'facebook_profile': (170, 170),
    'facebook_post': (1200, 630),
    'facebook_cover': (820, 312),
    'twitter_profile': (400, 400),
    'twitter_post': (1024, 512),
    'twitter_header': (1500, 500),
    'youtube_profile': (800, 800),
    'youtube_thumbnail': (1280, 720),
    'youtube_banner': (2560, 1440),
    'linkedin_profile': (400, 400),
    'linkedin_post': (1104, 736),
    'linkedin_banner': (1128, 191),
    'tiktok_profile': (200, 200),
    'tiktok_video': (1080, 1920),
    'slack': (512, 512),
    'discord': (512, 512)
}
        
def _get_base(image_path):
    base_dir = os.path.dirname(image_path)
    base_name = os.path.splitext(os.path.basename(image_path))[0]
    return base_dir, base_name

# =====================
# LogoProcessor Class
# =====================
class LogoProcessor:
    """
    Robust logo processor supporting all basic, effects, and social variations.
    Each method outputs files in the same directory as the input, using the format 'filename'_(variation).filetype.
    """
    def __init__(self, cache_dir=None, cache_folder=None, upload_folder=None, output_folder=None, temp_folder=None, use_parallel=True, max_workers=16):
        """Initialize LogoProcessor with ultra-fast optimizations while maintaining quality"""
        self.logger = logging.getLogger(__name__)
        
        # Ultra-fast processing settings (maintaining quality)
        self.ultra_fast_mode = True  # Enable ultra-fast mode for 10-second target
        self.use_cache = True  # Enable aggressive caching
        self.parallel_processing = True  # Enable parallel processing
        self.optimize_algorithms = True  # Use optimized algorithms
        
        # Configure paths
        self.cache_dir = cache_dir or os.path.join(os.getcwd(), 'cache')
        self.cache_folder = cache_folder or os.path.join(os.getcwd(), 'cache')
        self.upload_folder = upload_folder or os.path.join(os.getcwd(), 'uploads')
        self.output_folder = output_folder or os.path.join(os.getcwd(), 'outputs')
        self.temp_folder = temp_folder or os.path.join(os.getcwd(), 'temp')
        
        # Create directories if they don't exist
        for folder in [self.cache_dir, self.cache_folder, self.upload_folder, self.output_folder, self.temp_folder]:
            os.makedirs(folder, exist_ok=True)
        
        # Ultra-fast processing settings
        self.use_parallel = use_parallel
        self.max_workers = max_workers * 2 if self.ultra_fast_mode else max_workers  # Double workers in ultra-fast mode
        
        # Performance tracking
        self.processing_times = {}
        self.cache_hits = 0
        self.cache_misses = 0
        
        # Initialize cache
        if self.use_cache:
            self._init_cache()
        
                # Initialize social media sizes
        self.social_sizes = DEFAULT_SOCIAL_SIZES
        
        self.logger.info(f"‚ö° LogoProcessor initialized in ultra-fast mode with {self.max_workers} workers (quality maintained)")
    
    def _init_cache(self):
        """Initialize ultra-fast cache system"""
        self.cache = {}
        self.cache_dir = os.path.join(self.cache_folder, 'ultra_fast')
        os.makedirs(self.cache_dir, exist_ok=True)
        self.logger.info(f"‚ö° Ultra-fast cache initialized at {self.cache_dir}")
    
    def _get_cache_key(self, file_path, operation):
        """Generate cache key for ultra-fast caching"""
        file_hash = hashlib.md5(open(file_path, 'rb').read()).hexdigest()
        return f"{operation}_{file_hash}"
    
    def _get_cached_result(self, cache_key):
        """Get cached result for ultra-fast processing"""
        if not self.use_cache:
            return None
        
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.pkl")
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'rb') as f:
                    result = pickle.load(f)
                self.cache_hits += 1
                self.logger.info(f"‚ö° Cache hit for {cache_key}")
                return result
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Cache read error: {str(e)}")
        
        self.cache_misses += 1
        return None
    
    def _cache_result(self, cache_key, result):
        """Cache result for ultra-fast processing"""
        if not self.use_cache:
            return
        
        try:
            cache_file = os.path.join(self.cache_dir, f"{cache_key}.pkl")
            with open(cache_file, 'wb') as f:
                pickle.dump(result, f)
            self.logger.info(f"‚ö° Cached result for {cache_key}")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Cache write error: {str(e)}")
    
    def _optimized_image_processing(self, img, target_size=None, quality=95):
        """Optimized image processing with maintained quality for speed"""
        if self.ultra_fast_mode and self.optimize_algorithms:
            # Use optimized algorithms while maintaining quality
            if target_size:
                # Use LANCZOS for better quality and reasonable speed
                img = img.resize(target_size, Image.LANCZOS)
            
            # Maintain original quality
            return img, quality
        
        return img, quality

    # ----------- Basic Variations -----------
    def _create_transparent_png(self, image_path):
        """Create transparent PNG version with ultra-fast optimization"""
        cache_key = self._get_cache_key(image_path, 'transparent_png')
        cached_result = self._get_cached_result(cache_key)
        if cached_result:
            return cached_result
        
        try:
            self.logger.info(f"‚ö° Creating transparent PNG: {os.path.basename(image_path)}")
            
            # Load image with optimized processing
            img = Image.open(image_path).convert('RGBA')
            
            # Use the proper smart background removal method
            img = self._smart_background_removal(img)
            
            # Save with maintained quality
            output_path = os.path.join(self.output_folder, f"{os.path.splitext(os.path.basename(image_path))[0]}_transparent.png")
            img.save(output_path, 'PNG', optimize=True)
            
            result = output_path
            self._cache_result(cache_key, result)
            self.logger.info(f"‚ö° Transparent PNG created: {output_path}")
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå Error creating transparent PNG: {str(e)}")
            return None
    
    def _smart_background_removal_fast(self, img):
        """Ultra-fast background removal while maintaining quality"""
        try:
            # Convert to numpy array for faster processing
            img_array = np.array(img)
            
            # Use optimized background detection
            if self.ultra_fast_mode:
                # Use faster color-based background removal
                return self._fast_color_based_removal(img_array)
            else:
                return self._smart_background_removal(img)
                
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Fast background removal failed, using fallback: {str(e)}")
            return self._simple_background_removal(img)
    
    def _fast_color_based_removal(self, img_array):
        """Fast color-based background removal"""
        try:
            # Convert to HSV for better color detection
            hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)
            
            # Detect background color (assume white/light background)
            # Use optimized thresholds for speed
            lower_white = np.array([0, 0, 200])
            upper_white = np.array([180, 30, 255])
            
            # Create mask
            mask = cv2.inRange(hsv, lower_white, upper_white)
            mask = cv2.bitwise_not(mask)
            
            # Apply mask
            result = img_array.copy()
            result[mask == 0] = [0, 0, 0, 0]  # Make background transparent
            
            return Image.fromarray(result, 'RGBA')
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Color-based removal failed: {str(e)}")
            return Image.fromarray(img_array, 'RGBA')
    
    def _smart_background_removal(self, img):
        """Smart background removal with multi-color support"""
        try:
            # Convert to numpy array for processing
            img_array = np.array(img)
            
            # Detect background color
            background_color = self._detect_background_color(img)
            self.logger.info(f"üé® Detected background color: RGB{background_color}")
            
            # Check if OpenCV is available for advanced processing
            if CV2_AVAILABLE:
                # Create mask based on color difference
                color_diff = np.sqrt(np.sum((img_array[:, :, :3].astype(float) - background_color[:3]) ** 2, axis=2))
                
                # Use adaptive threshold
                threshold = np.std(color_diff) * 1.5
                mask = (color_diff > threshold).astype(np.uint8) * 255
                
                # Clean up mask with morphological operations
                kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
                mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
                mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
                
                # Apply mask to create transparent background
                result = img_array.copy()
                result[mask == 0] = [0, 0, 0, 0]
                
                return Image.fromarray(result, 'RGBA')
            else:
                # Fallback to simple background removal without OpenCV
                self.logger.warning("‚ö†Ô∏è OpenCV not available, using simple background removal")
                return self._simple_background_removal(img)
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Smart background removal failed: {str(e)}")
            return self._simple_background_removal(img)
    
    def _detect_background_color(self, img):
        """Detect the dominant background color from image edges"""
        try:
            # Convert to RGB for color analysis
            rgb_img = img.convert('RGB')
            
            # Get the corners and edges to determine background color
            width, height = rgb_img.size
            
            # Sample colors from corners and edges
            sample_points = [
                (0, 0),  # Top-left
                (width-1, 0),  # Top-right
                (0, height-1),  # Bottom-left
                (width-1, height-1),  # Bottom-right
                (width//2, 0),  # Top-center
                (width//2, height-1),  # Bottom-center
                (0, height//2),  # Left-center
                (width-1, height//2),  # Right-center
            ]
            
            colors = []
            for x, y in sample_points:
                try:
                    color = rgb_img.getpixel((x, y))
                    colors.append(color)
                except:
                    continue
            
            if not colors:
                return (255, 255, 255)  # Default to white
            
            # Find the most common color (background)
            from collections import Counter
            color_counts = Counter(colors)
            background_color = color_counts.most_common(1)[0][0]
            
            return background_color
            
        except Exception as e:
            self.logger.warning(f'‚ö†Ô∏è Could not extract background color: {e}')
            return (255, 255, 255)  # Default to white
    
    def _simple_background_removal(self, img):
        """Simple background removal as fallback"""
        try:
            # Convert to RGBA if not already
            if img.mode != 'RGBA':
                img = img.convert('RGBA')
            
            # Get image data
            data = np.array(img)
            
            # Detect background color
            background_color = self._detect_background_color(img)
            self.logger.info(f"üé® Simple removal using background color: RGB{background_color}")
            
            # Create mask for background color with tolerance
            r, g, b, a = data[:, :, 0], data[:, :, 1], data[:, :, 2], data[:, :, 3]
            
            # Use tolerance for background color matching
            tolerance = 30
            bg_r, bg_g, bg_b = background_color[:3]
            
            # Create mask for background color with tolerance
            mask = ((np.abs(r - bg_r) <= tolerance) & 
                   (np.abs(g - bg_g) <= tolerance) & 
                   (np.abs(b - bg_b) <= tolerance))
            
            # Make background transparent
            data[mask] = [0, 0, 0, 0]
            
            return Image.fromarray(data, 'RGBA')
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Simple background removal failed: {str(e)}")
            return img  # Return original image if all else fails
    
    def _create_black_version(self, image_path):
        """Create black version with ultra-fast optimization"""
        cache_key = self._get_cache_key(image_path, 'black_version')
        cached_result = self._get_cached_result(cache_key)
        if cached_result:
            return cached_result
        
        try:
            self.logger.info(f"‚ö° Creating black version: {os.path.basename(image_path)}")
            
            # Load image
            img = Image.open(image_path).convert('RGBA')
            
            # Create black version with maintained quality
            black_img = Image.new('RGBA', img.size, (0, 0, 0, 0))
            black_img.paste(img, (0, 0), img)
            
            # Save with maintained quality
            output_path = os.path.join(self.output_folder, f"{os.path.splitext(os.path.basename(image_path))[0]}_black.png")
            black_img.save(output_path, 'PNG', optimize=True)
            
            result = output_path
            self._cache_result(cache_key, result)
            self.logger.info(f"‚ö° Black version created: {output_path}")
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå Error creating black version: {str(e)}")
            return None
    
    def _create_pdf_version(self, image_path):
        """Create PDF version with ultra-fast optimization"""
        cache_key = self._get_cache_key(image_path, 'pdf_version')
        cached_result = self._get_cached_result(cache_key)
        if cached_result:
            return cached_result
        
        try:
            self.logger.info(f"‚ö° Creating PDF version: {os.path.basename(image_path)}")
            
            # Load image
            img = Image.open(image_path).convert('RGB')
            
            # Save as PDF with maintained quality
            output_path = os.path.join(self.output_folder, f"{os.path.splitext(os.path.basename(image_path))[0]}.pdf")
            img.save(output_path, 'PDF', resolution=300.0)
            
            result = output_path
            self._cache_result(cache_key, result)
            self.logger.info(f"‚ö° PDF version created: {output_path}")
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå Error creating PDF version: {str(e)}")
            return None
    
    def _create_webp_version(self, image_path):
        """Create WebP version with ultra-fast optimization"""
        cache_key = self._get_cache_key(image_path, 'webp_version')
        cached_result = self._get_cached_result(cache_key)
        if cached_result:
            return cached_result
        
        try:
            self.logger.info(f"‚ö° Creating WebP version: {os.path.basename(image_path)}")
            
            # Load image
            img = Image.open(image_path).convert('RGBA')
            
            # Save as WebP with maintained quality
            output_path = os.path.join(self.output_folder, f"{os.path.splitext(os.path.basename(image_path))[0]}.webp")
            img.save(output_path, 'WEBP', quality=95, method=6)
            
            result = output_path
            self._cache_result(cache_key, result)
            self.logger.info(f"‚ö° WebP version created: {output_path}")
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå Error creating WebP version: {str(e)}")
            return None
    
    def _create_favicon(self, image_path):
        base_dir, base_name = _get_base(image_path)
        favicon_path = os.path.join(base_dir, f"{base_name}_favicon.ico")
        img = Image.open(image_path).convert("RGBA")
        sizes = [(16, 16), (32, 32), (48, 48), (64, 64), (128, 128), (256, 256)]
        icons = [img.resize(size, Image.LANCZOS) for size in sizes]
        icons[0].save(favicon_path, format='ICO', sizes=sizes)
        return {"ico": favicon_path}

    def _create_email_header(self, image_path):
        base_dir, base_name = _get_base(image_path)
        header_path = os.path.join(base_dir, f"{base_name}_emailheader.png")
        img = Image.open(image_path).convert("RGBA")
        header = Image.new("RGBA", (600, 200), (255, 255, 255, 0))
        logo_w, logo_h = img.size
        scale = min(500 / logo_w, 150 / logo_h, 1)
        logo_resized = img.resize((int(logo_w * scale), int(logo_h * scale)), Image.LANCZOS)
        x = (600 - logo_resized.size[0]) // 2
        y = (200 - logo_resized.size[1]) // 2
        header.paste(logo_resized, (x, y), logo_resized)
        header.save(header_path)
        return {"png": header_path}

    # ----------- Effects -----------
    def _create_vector_trace(self, image_path):
        """Create single-color vector trace using vtracer"""
        self.logger.info(f'üî∑ Starting vector trace processing for: {os.path.basename(image_path)}')
        
        try:
            result = self.generate_vector_trace(image_path, {})
            if result.get('status') == 'success' and result.get('output_paths'):
                output_paths = result['output_paths']
                out = {}
                if output_paths.get('svg'):
                    out["svg"] = output_paths['svg']
                if output_paths.get('pdf'):
                    out["pdf"] = output_paths['pdf']
                if output_paths.get('eps'):
                    out["eps"] = output_paths['eps']
                
                self.logger.info(f'‚úÖ Vector trace completed: {len(out)} files generated')
                return out
            else:
                self.logger.error(f'‚ùå Vector trace failed: {result.get("message", "Unknown error")}')
                return {}
        except Exception as e:
            self.logger.error(f'‚ùå Vector trace exception: {str(e)}')
            return {}

    def _create_full_color_vector_trace(self, image_path):
        """Create full-color vector trace using vtracer"""
        self.logger.info(f'üé® Starting full color vector trace processing for: {os.path.basename(image_path)}')
        
        try:
            result = self.generate_vector_trace(image_path, {})
            if result.get('status') == 'success' and result.get('output_paths'):
                output_paths = result['output_paths']
                out = {}
                if output_paths.get('svg'):
                    out["svg"] = output_paths['svg']
                if output_paths.get('pdf'):
                    out["pdf"] = output_paths['pdf']
                if output_paths.get('eps'):
                    out["eps"] = output_paths['eps']
                
                self.logger.info(f'‚úÖ Full color vector trace completed: {len(out)} files generated')
                return out
            else:
                self.logger.error(f'‚ùå Full color vector trace failed: {result.get("message", "Unknown error")}')
                return {}
        except Exception as e:
            self.logger.error(f'‚ùå Full color vector trace exception: {str(e)}')
            return {}

    def _create_color_separations(self, image_path):
        """Advanced color separation with PMS detection and proper print setup"""
        try:
            self.logger.info(f"üé® Starting color separations for: {image_path}")
            
            base_dir, base_name = _get_base(image_path)
            
            # Load and analyze image
            self.logger.info("üì∏ Loading image for color analysis...")
            img = Image.open(image_path).convert("RGBA")
            arr = np.array(img)
            
            # Extract non-transparent pixels for color analysis
            alpha_mask = arr[..., 3] > 0
            rgb_pixels = arr[alpha_mask][..., :3]
            
            if len(rgb_pixels) == 0:
                self.logger.warning("‚ö†Ô∏è No visible pixels found in image")
                return {"error": "No visible pixels found"}
            
            self.logger.info(f"üìä Found {len(rgb_pixels)} visible pixels for color analysis")
            
            # Detect unique colors and merge similar ones
            if KMeans is None:
                self.logger.error("‚ùå scikit-learn is required for color separations but not available")
                raise ImportError("scikit-learn is required for color separations.")
            
            self.logger.info("üîç Performing K-means clustering for color detection...")
            
            # Initial color detection with higher cluster count
            initial_clusters = min(20, len(np.unique(rgb_pixels.reshape(-1, 3), axis=0)))
            self.logger.info(f"üéØ Using {initial_clusters} initial clusters for color detection")
            
            kmeans_initial = KMeans(n_clusters=initial_clusters, random_state=42, n_init=3)
            kmeans_initial.fit(rgb_pixels)
            
            # Merge similar colors (within 30 units in RGB space)
            unique_colors = []
            color_threshold = 30
            
            for center in kmeans_initial.cluster_centers_:
                is_similar = False
                for existing_color in unique_colors:
                    # Calculate Euclidean distance in RGB space
                    distance = np.sqrt(np.sum((center - existing_color) ** 2))
                    if distance < color_threshold:
                        is_similar = True
                        break
                if not is_similar:
                    unique_colors.append(center)
            
            num_colors = len(unique_colors)
            self.logger.info(f"üé® Detected {num_colors} unique colors after merging similar ones")
            
            # Artboard setup (13" x 19" at 300 DPI)
            artboard_width = int(13 * 300)  # 3900 pixels
            artboard_height = int(19 * 300)  # 5700 pixels
            logo_width = int(10 * 300)  # 3000 pixels
            
            # Calculate logo scaling to fit 10" width
            original_width = img.width
            scale_factor = logo_width / original_width
            logo_height = int(img.height * scale_factor)
            
            # Center position on artboard
            center_x = (artboard_width - logo_width) // 2
            center_y = (artboard_height - logo_height) // 2
            
            # Registration mark setup
            reg_mark_size = 30
            reg_positions = [
                (reg_mark_size, reg_mark_size),  # Top-left
                (artboard_width - reg_mark_size * 2, reg_mark_size),  # Top-right
                (reg_mark_size, artboard_height - reg_mark_size * 2),  # Bottom-left
                (artboard_width - reg_mark_size * 2, artboard_height - reg_mark_size * 2)  # Bottom-right
            ]
            
            def create_registration_marks(svg_root):
                """Add registration marks to SVG"""
                for x, y in reg_positions:
                    # Create registration mark (circle with crosshairs)
                    group = etree.SubElement(svg_root, 'g')
                    # Outer circle
                    etree.SubElement(group, 'circle', 
                                   cx=str(x + reg_mark_size//2), cy=str(y + reg_mark_size//2), 
                                   r=str(reg_mark_size//2), fill="none", stroke="black", 
                                   **{"stroke-width": "1"})
                    # Horizontal line
                    etree.SubElement(group, 'line', 
                                   x1=str(x), y1=str(y + reg_mark_size//2),
                                   x2=str(x + reg_mark_size), y2=str(y + reg_mark_size//2),
                                   stroke="black", **{"stroke-width": "1"})
                    # Vertical line  
                    etree.SubElement(group, 'line',
                                   x1=str(x + reg_mark_size//2), y1=str(y),
                                   x2=str(x + reg_mark_size//2), y2=str(y + reg_mark_size),
                                   stroke="black", **{"stroke-width": "1"})
            
            separations = []
            
            if num_colors <= 4:
                # PMS spot color separation
                self.logger.info(f"Creating {num_colors} PMS spot color separations")
                
                for i, color in enumerate(unique_colors):
                    self.logger.info(f"üé® Processing color {i+1}/{num_colors}: RGB{tuple(map(int, color))}")
                    
                    # Create mask for this color
                    color_mask = np.zeros(arr.shape[:2], dtype=bool)
                    for y in range(arr.shape[0]):
                        for x in range(arr.shape[1]):
                            if alpha_mask[y, x]:
                                pixel = arr[y, x, :3]
                                distance = np.sqrt(np.sum((pixel - color) ** 2))
                                if distance < color_threshold:
                                    color_mask[y, x] = True
                    
                    # Create separation image
                    sep_img = Image.new("RGBA", (artboard_width, artboard_height), (255, 255, 255, 0))
                    
                    # Resize and place logo
                    logo_sep = Image.new("RGBA", img.size, (255, 255, 255, 0))
                    for y in range(img.height):
                        for x in range(img.width):
                            if color_mask[y, x]:
                                logo_sep.putpixel((x, y), tuple(map(int, color)) + (255,))
                    
                    # Scale and center logo
                    logo_resized = logo_sep.resize((logo_width, logo_height), Image.Resampling.LANCZOS)
                    sep_img.paste(logo_resized, (center_x, center_y), logo_resized)
                    
                    # Save PNG
                    png_path = os.path.join(base_dir, f"{base_name}_pms_{i+1}.png")
                    sep_img.save(png_path, "PNG")
                    self.logger.info(f"üíæ Saved PNG separation: {png_path}")
                    
                    # Create AI/SVG file
                    svg_path = os.path.join(base_dir, f"{base_name}_pms_{i+1}.svg")
                    ai_path = os.path.join(base_dir, f"{base_name}_pms_{i+1}.ai")
                    
                    # Create SVG
                    svg_root = etree.Element('svg', xmlns="http://www.w3.org/2000/svg",
                                           width=str(artboard_width), height=str(artboard_height))
                    
                    # Add logo paths (simplified for this implementation)
                    color_hex = f"#{int(color[0]):02x}{int(color[1]):02x}{int(color[2]):02x}"
                    
                    # Convert logo to paths (simplified contour approach)
                    if cv2 is not None:
                        logo_gray = cv2.cvtColor(np.array(logo_sep), cv2.COLOR_RGBA2GRAY)
                        contours, _ = cv2.findContours(logo_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        
                        for contour in contours:
                            if cv2.contourArea(contour) > 100:
                                # Scale contour to final size and position
                                scaled_contour = contour * scale_factor
                                scaled_contour[:, :, 0] += center_x
                                scaled_contour[:, :, 1] += center_y
                                
                                points = scaled_contour.reshape(-1, 2)
                                if len(points) > 2:
                                    path_data = f"M {points[0][0]},{points[0][1]}"
                                    for point in points[1:]:
                                        path_data += f" L {point[0]},{point[1]}"
                                    path_data += " Z"
                                    etree.SubElement(svg_root, 'path', d=path_data, fill=color_hex)
                    
                    # Add registration marks
                    create_registration_marks(svg_root)
                    
                    # Save SVG
                    svg_data = etree.tostring(svg_root, pretty_print=True).decode()
                    with open(svg_path, 'w') as f:
                        f.write(svg_data)
                    self.logger.info(f"üíæ Saved SVG separation: {svg_path}")
                    
                    # Copy SVG to AI (AI format is SVG-based)
                    with open(ai_path, 'w') as f:
                        f.write(svg_data)
                    self.logger.info(f"üíæ Saved AI separation: {ai_path}")
                    
                    separations.append({
                        'png': png_path,
                        'svg': svg_path,
                        'ai': ai_path,
                        'color': tuple(map(int, color))
                    })
            else:
                # CMYK process separation
                self.logger.info("Creating CMYK process separations")
                
                def rgb_to_cmyk(r, g, b):
                    """Convert RGB to CMYK"""
                    r, g, b = r/255, g/255, b/255
                    k = 1 - max(r, g, b)
                    if k == 1:
                        c = m = y = 0
                    else:
                        c = (1 - r - k) / (1 - k)
                        m = (1 - g - k) / (1 - k)
                        y = (1 - b - k) / (1 - k)
                    return c, m, y, k
                
                # Create CMYK separations
                cmyk_channels = ['cyan', 'magenta', 'yellow', 'black']
                cmyk_colors = [(0, 255, 255), (255, 0, 255), (255, 255, 0), (0, 0, 0)]
                
                for i, (channel, color) in enumerate(zip(cmyk_channels, cmyk_colors)):
                    self.logger.info(f"üé® Processing {channel} channel")
                    
                    # Create separation image
                    sep_img = Image.new("RGBA", (artboard_width, artboard_height), (255, 255, 255, 0))
                    
                    # Convert image to CMYK and extract channel
                    rgb_img = img.convert("RGB")
                    rgb_array = np.array(rgb_img)
                    
                    # Create channel mask
                    channel_mask = np.zeros(arr.shape[:2], dtype=bool)
                    for y in range(arr.shape[0]):
                        for x in range(arr.shape[1]):
                            if alpha_mask[y, x]:
                                pixel = rgb_array[y, x]
                                c, m, y_val, k = rgb_to_cmyk(*pixel)
                                if i == 0 and c > 0.1:  # Cyan
                                    channel_mask[y, x] = True
                                elif i == 1 and m > 0.1:  # Magenta
                                    channel_mask[y, x] = True
                                elif i == 2 and y_val > 0.1:  # Yellow
                                    channel_mask[y, x] = True
                                elif i == 3 and k > 0.1:  # Black
                                    channel_mask[y, x] = True
                    
                    # Create channel image
                    channel_img = Image.new("RGBA", img.size, (255, 255, 255, 0))
                    for y in range(img.height):
                        for x in range(img.width):
                            if channel_mask[y, x]:
                                channel_img.putpixel((x, y), color + (255,))
                    
                    # Scale and center logo
                    channel_resized = channel_img.resize((logo_width, logo_height), Image.Resampling.LANCZOS)
                    sep_img.paste(channel_resized, (center_x, center_y), channel_resized)
                    
                    # Save files
                    png_path = os.path.join(base_dir, f"{base_name}_cmyk_{channel}.png")
                    svg_path = os.path.join(base_dir, f"{base_name}_cmyk_{channel}.svg")
                    ai_path = os.path.join(base_dir, f"{base_name}_cmyk_{channel}.ai")
                    
                    sep_img.save(png_path, "PNG")
                    self.logger.info(f"üíæ Saved {channel} PNG: {png_path}")
                    
                    # Create SVG
                    svg_root = etree.Element('svg', xmlns="http://www.w3.org/2000/svg",
                                           width=str(artboard_width), height=str(artboard_height))
                    
                    # Add logo paths
                    color_hex = f"#{color[0]:02x}{color[1]:02x}{color[2]:02x}"
                    
                    if cv2 is not None:
                        channel_gray = cv2.cvtColor(np.array(channel_img), cv2.COLOR_RGBA2GRAY)
                        contours, _ = cv2.findContours(channel_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        
                        for contour in contours:
                            if cv2.contourArea(contour) > 100:
                                scaled_contour = contour * scale_factor
                                scaled_contour[:, :, 0] += center_x
                                scaled_contour[:, :, 1] += center_y
                                
                                points = scaled_contour.reshape(-1, 2)
                                if len(points) > 2:
                                    path_data = f"M {points[0][0]},{points[0][1]}"
                                    for point in points[1:]:
                                        path_data += f" L {point[0]},{point[1]}"
                                    path_data += " Z"
                                    etree.SubElement(svg_root, 'path', d=path_data, fill=color_hex)
                    
                    # Add registration marks
                    create_registration_marks(svg_root)
                    
                    # Save SVG
                    svg_data = etree.tostring(svg_root, pretty_print=True).decode()
                    with open(svg_path, 'w') as f:
                        f.write(svg_data)
                    self.logger.info(f"üíæ Saved {channel} SVG: {svg_path}")
                    
                    # Copy to AI
                    with open(ai_path, 'w') as f:
                        f.write(svg_data)
                    self.logger.info(f"üíæ Saved {channel} AI: {ai_path}")
                    
                    separations.append({
                        'png': png_path,
                        'svg': svg_path,
                        'ai': ai_path,
                        'channel': channel
                    })
            
            self.logger.info(f"‚úÖ Color separations completed successfully: {len(separations)} files created")
            return {
                'separations': separations,
                'num_colors': num_colors,
                'type': 'pms' if num_colors <= 4 else 'cmyk'
            }
            
        except ImportError as e:
            self.logger.error(f"‚ùå Import error in color separations: {str(e)}")
            raise
        except Exception as e:
            self.logger.error(f"‚ùå Error in color separations: {str(e)}")
            self.logger.error(f"‚ùå Exception type: {type(e).__name__}")
            import traceback
            self.logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
            raise

    def _create_distressed_version(self, image_path):
        """Apply aggressive raster distress filter to logo artwork with visible texture removal"""
        base_dir, base_name = _get_base(image_path)
        out_path = os.path.join(base_dir, f"{base_name}_distressed.png")
        
        # Load image and ensure RGBA
        img = Image.open(image_path).convert("RGBA")
        
        # Create alpha mask to identify active logo pixels only
        alpha_channel = img.split()[-1]
        alpha_array = np.array(alpha_channel)
        logo_mask = alpha_array > 0  # True where logo exists
        
        # Create aggressive distress patterns
        np.random.seed(42)  # For consistent results
        
        # Pattern 1: Large chunk removal (splatter effect)
        large_chunks = np.random.rand(img.height, img.width)
        large_removal = large_chunks > 0.85  # Remove 15% in large chunks
        
        # Pattern 2: Edge erosion (realistic wear)
        edge_erosion = np.random.rand(img.height, img.width)
        edge_removal = edge_erosion > 0.75  # Remove 25% along edges
        
        # Pattern 3: Speckled texture removal
        speckle_noise = np.random.rand(img.height, img.width)
        speckle_removal = speckle_noise > 0.70  # Remove 30% as speckles
        
        # Pattern 4: Scratches and streaks
        scratch_pattern = np.zeros((img.height, img.width), dtype=bool)
        num_scratches = 8
        for _ in range(num_scratches):
            # Random scratch direction and position
            start_x = np.random.randint(0, img.width)
            start_y = np.random.randint(0, img.height)
            angle = np.random.rand() * 2 * np.pi
            length = np.random.randint(20, min(img.width, img.height) // 3)
            width = np.random.randint(2, 6)
            
            # Draw scratch
            for i in range(length):
                x = int(start_x + i * np.cos(angle))
                y = int(start_y + i * np.sin(angle))
                
                # Create scratch width
                for dx in range(-width//2, width//2 + 1):
                    for dy in range(-width//2, width//2 + 1):
                        scratch_x = x + dx
                        scratch_y = y + dy
                        if 0 <= scratch_x < img.width and 0 <= scratch_y < img.height:
                            scratch_pattern[scratch_y, scratch_x] = True
        
        # Combine all distress patterns
        combined_distress = large_removal | edge_removal | speckle_removal | scratch_pattern
        
        # Apply morphological operations for more realistic grunge
        if cv2 is not None:
            # Create organic, connected distress regions
            kernel_large = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
            combined_distress = cv2.morphologyEx(
                combined_distress.astype(np.uint8), 
                cv2.MORPH_CLOSE, 
                kernel_large
            ).astype(bool)
            
            # Add some dilation for chunky effects
            kernel_dilate = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            combined_distress = cv2.dilate(
                combined_distress.astype(np.uint8), 
                kernel_dilate
            ).astype(bool)
        
        # Apply AGGRESSIVE edge detection for realistic wear patterns
        if cv2 is not None:
            # Convert logo mask to find edges
            logo_mask_uint8 = logo_mask.astype(np.uint8) * 255
            edges = cv2.Canny(logo_mask_uint8, 50, 150)
            edge_pixels = edges > 0
            
            # Make edges more susceptible to distress (80% removal chance at edges)
            edge_distress = np.random.rand(img.height, img.width) > 0.2
            combined_distress = combined_distress | (edge_pixels & edge_distress)
        
        # Ensure we don't remove more than 60% (keep at least 40%)
        logo_pixel_count = np.sum(logo_mask)
        potential_removed = np.sum(logo_mask & combined_distress)
        removal_ratio = potential_removed / logo_pixel_count if logo_pixel_count > 0 else 0
        
        if removal_ratio > 0.60:
            # Reduce distress to maintain 40% minimum
            target_removal = 0.55  # Target 55% removal (keeping 45%)
            reduction_factor = target_removal / removal_ratio
            
            # Randomly keep some pixels that would be removed
            random_keep = np.random.rand(img.height, img.width) < (1 - reduction_factor)
            combined_distress = combined_distress & ~random_keep
        
        # Create final distressed image with dramatic effect
        result_img = Image.new("RGBA", img.size, (255, 255, 255, 0))
        img_array = np.array(img)
        
        # Apply distress only to active logo pixels
        for y in range(img.height):
            for x in range(img.width):
                if logo_mask[y, x]:  # Only process logo pixels
                    if not combined_distress[y, x]:  # Keep pixel if not distressed away
                        # Keep original pixel but add slight aging/darkening
                        original_r, original_g, original_b, original_a = img_array[y, x]
                        
                        # Add subtle aging effect to remaining pixels
                        aging_factor = 0.9  # Darken slightly
                        aged_r = int(original_r * aging_factor)
                        aged_g = int(original_g * aging_factor) 
                        aged_b = int(original_b * aging_factor)
                        
                        result_img.putpixel((x, y), (aged_r, aged_g, aged_b, original_a))
        
        # Add realistic wear patterns around remaining edges
        result_array = np.array(result_img)
        
        # Create soft edges around distressed areas for realism
        for y in range(1, img.height - 1):
            for x in range(1, img.width - 1):
                # Check if this pixel was kept but is adjacent to distressed area
                if logo_mask[y, x] and not combined_distress[y, x]:
                    # Count distressed neighbors
                    distressed_neighbors = 0
                    for dy in [-1, 0, 1]:
                        for dx in [-1, 0, 1]:
                            if dy == 0 and dx == 0:
                                continue
                            ny, nx = y + dy, x + dx
                            if (0 <= ny < img.height and 0 <= nx < img.width and
                                logo_mask[ny, nx] and combined_distress[ny, nx]):
                                distressed_neighbors += 1
                    
                    # If adjacent to 3+ distressed pixels, add edge wear
                    if distressed_neighbors >= 3:
                        current_pixel = list(result_array[y, x])
                        if current_pixel[3] > 0:  # If pixel has alpha
                            # Create frayed edge effect
                            if np.random.rand() > 0.7:  # 30% chance to fray
                                current_pixel[3] = int(current_pixel[3] * 0.3)  # Heavy alpha reduction
                            else:
                                current_pixel[3] = int(current_pixel[3] * 0.7)  # Moderate alpha reduction
                            result_array[y, x] = current_pixel
        
        # Convert back to PIL Image
        result_img = Image.fromarray(result_array)
        
        # Save the result as PNG with transparent background
        result_img.save(out_path, "PNG", optimize=True)
        
        # Verify the distress worked by checking remaining pixels
        final_alpha = np.array(result_img.split()[-1])
        remaining_pixels = np.sum(final_alpha > 0)
        original_pixels = np.sum(logo_mask)
        actual_retention = remaining_pixels / original_pixels if original_pixels > 0 else 0
        
        self.logger.info(f"Distressed effect applied: {actual_retention:.1%} of logo retained ({100 - actual_retention*100:.1f}% removed)")
        
        return out_path

    def _create_halftone(self, image_path):
        """Apply halftone dot pattern to logo only, maintaining original colors"""
        self.logger.info(f'üîò Starting halftone effect processing for: {os.path.basename(image_path)}')
        
        base_dir, base_name = _get_base(image_path)
        out_path = os.path.join(base_dir, f"{base_name}_halftone.png")
        
        # Load image and ensure RGBA
        self.logger.info('üì∏ Loading image for halftone processing...')
        img = Image.open(image_path).convert("RGBA")
        self.logger.info(f'üìê Image dimensions: {img.size[0]}x{img.size[1]} pixels')
        
        # Create alpha mask to identify logo vs background
        self.logger.info('üé≠ Creating alpha mask for logo detection...')
        alpha_channel = img.split()[-1]
        alpha_array = np.array(alpha_channel)
        logo_mask = alpha_array > 0  # True where logo exists
        
        logo_pixel_count = np.sum(logo_mask)
        total_pixels = img.size[0] * img.size[1]
        logo_coverage = (logo_pixel_count / total_pixels) * 100
        
        self.logger.info(f'üéØ Logo coverage: {logo_pixel_count:,} pixels ({logo_coverage:.1f}% of image)')
        
        # Create result image
        result_img = Image.new("RGBA", img.size, (255, 255, 255, 0))
        result_array = np.array(result_img)
        img_array = np.array(img)
        
        # Halftone parameters
        dot_spacing = 8  # Distance between dot centers
        max_dot_size = dot_spacing - 2  # Maximum dot radius
        
        self.logger.info(f'üîò Halftone parameters: dot spacing={dot_spacing}, max dot size={max_dot_size}')
        
        # Process in a grid pattern
        self.logger.info('üîÑ Processing halftone dots...')
        dots_created = 0
        
        for center_y in range(dot_spacing // 2, img.height, dot_spacing):
            for center_x in range(dot_spacing // 2, img.width, dot_spacing):
                
                # Sample area around this dot center
                sample_region = []
                logo_pixels_in_region = 0
                total_r, total_g, total_b = 0.0, 0.0, 0.0
                
                # Define sampling area
                sample_radius = dot_spacing // 2
                for dy in range(-sample_radius, sample_radius + 1):
                    for dx in range(-sample_radius, sample_radius + 1):
                        sample_x = center_x + dx
                        sample_y = center_y + dy
                        
                        if (0 <= sample_x < img.width and 0 <= sample_y < img.height):
                            if logo_mask[sample_y, sample_x]:
                                logo_pixels_in_region += 1
                                r, g, b, a = img_array[sample_y, sample_x]
                                total_r += float(r)
                                total_g += float(g)
                                total_b += float(b)
                
                # Skip if no logo pixels in this region
                if logo_pixels_in_region == 0:
                    continue
                
                # Calculate average color for this region
                avg_r = int(total_r / logo_pixels_in_region)
                avg_g = int(total_g / logo_pixels_in_region)
                avg_b = int(total_b / logo_pixels_in_region)
                
                # Calculate brightness/intensity for dot size
                brightness = (avg_r + avg_g + avg_b) / 3
                intensity = brightness / 255.0
                
                # Invert intensity for halftone effect (darker areas = larger dots)
                dot_intensity = 1.0 - intensity
                
                # Calculate dot size based on intensity
                dot_radius = int(dot_intensity * max_dot_size / 2)
                
                if dot_radius > 0:
                    dots_created += 1
                    # Draw halftone dot with original colors
                    for dy in range(-dot_radius, dot_radius + 1):
                        for dx in range(-dot_radius, dot_radius + 1):
                            dot_x = center_x + dx
                            dot_y = center_y + dy
                            
                            # Check if pixel is within dot radius
                            if (0 <= dot_x < img.width and 0 <= dot_y < img.height):
                                distance = np.sqrt(dx*dx + dy*dy)
                                
                                if distance <= dot_radius:
                                    # Only place dot where logo originally existed
                                    if logo_mask[dot_y, dot_x]:
                                        # Use original colors with slight darkening for halftone effect
                                        original_r, original_g, original_b, original_a = img_array[dot_y, dot_x]
                                        
                                        # Apply halftone darkening based on dot intensity
                                        halftone_factor = 0.7 + (0.3 * dot_intensity)  # Range: 0.7 to 1.0
                                        
                                        final_r = int(original_r * halftone_factor)
                                        final_g = int(original_g * halftone_factor)
                                        final_b = int(original_b * halftone_factor)
                                        
                                        # Smooth edge falloff for dots
                                        edge_factor = 1.0
                                        if distance > dot_radius - 1:
                                            edge_factor = dot_radius - distance
                                        
                                        if edge_factor > 0:
                                            result_array[dot_y, dot_x] = [
                                                int(final_r * edge_factor),
                                                int(final_g * edge_factor), 
                                                int(final_b * edge_factor),
                                                int(original_a * edge_factor)
                                            ]
        
        self.logger.info(f'üîò Created {dots_created:,} halftone dots')
        
        # Alternative approach: More traditional halftone with dot patterns
        # This creates more uniform, print-like halftone dots
        
        # Create a more traditional halftone pattern
        self.logger.info('üîÑ Creating traditional halftone pattern...')
        traditional_result = Image.new("RGBA", img.size, (255, 255, 255, 0))
        
        # Convert to grayscale for dot size calculation, but keep original colors
        gray = img.convert("L")
        gray_array = np.array(gray)
        
        # Halftone dot spacing and angle
        dot_size = 6
        angle = 15  # degrees
        
        self.logger.info(f'üîò Traditional halftone: dot size={dot_size}, angle={angle}¬∞')
        
        # Create halftone pattern
        traditional_dots = 0
        for y in range(0, img.height, dot_size):
            for x in range(0, img.width, dot_size):
                
                # Sample original image in this cell
                cell_pixels = []
                cell_colors = []
                
                for dy in range(dot_size):
                    for dx in range(dot_size):
                        px, py = x + dx, y + dy
                        if (px < img.width and py < img.height and logo_mask[py, px]):
                            cell_pixels.append(gray_array[py, px])
                            cell_colors.append(img_array[py, px, :3])  # RGB only
                
                if not cell_pixels:
                    continue
                    
                # Calculate average brightness and color
                avg_brightness = np.mean(cell_pixels)
                avg_color = np.mean(cell_colors, axis=0).astype(int)
                
                # Calculate dot size (darker = larger dots)
                brightness_ratio = avg_brightness / 255.0
                dot_radius = int((1.0 - brightness_ratio) * (dot_size // 2))
                
                if dot_radius > 0:
                    traditional_dots += 1
                    # Draw circular dot in center of cell
                    center_x = x + dot_size // 2
                    center_y = y + dot_size // 2
                    
                    for dy in range(-dot_radius, dot_radius + 1):
                        for dx in range(-dot_radius, dot_radius + 1):
                            dot_x = center_x + dx
                            dot_y = center_y + dy
                            
                            if (0 <= dot_x < img.width and 0 <= dot_y < img.height):
                                distance = np.sqrt(dx*dx + dy*dy)
                                
                                if distance <= dot_radius and logo_mask[dot_y, dot_x]:
                                    # Use averaged color for this cell
                                    traditional_result.putpixel((dot_x, dot_y), 
                                                              tuple(avg_color.tolist()) + (255,))
        
        self.logger.info(f'üîò Created {traditional_dots:,} traditional halftone dots')
        
        # Use the traditional halftone result
        result_img = traditional_result
        
        # Save the result
        self.logger.info(f'üíæ Saving halftone result to: {out_path}')
        result_img.save(out_path, "PNG", optimize=True)
        
        # Verify the result
        final_file_size = os.path.getsize(out_path)
        self.logger.info(f'‚úÖ Halftone effect completed: {final_file_size:,} bytes')
        
        return out_path

    # ----------- Social -----------
    def _create_social_formats(self, image_path, selected_formats=None):
        """Create social media format variations that maintain the exact structure and content of the original design"""
        self.logger.info(f'üé® Starting social media repurposing for: {os.path.basename(image_path)}')
        
        base_dir, base_name = _get_base(image_path)
        file_ext = os.path.splitext(image_path)[1].lower()
        
        # Load the original image
        try:
            if file_ext == '.pdf':
                if PDF2IMAGE_AVAILABLE:
                    try:
                        from pdf2image import convert_from_path
                        images = convert_from_path(image_path, first_page=0, last_page=0)
                        if images:
                            original_img = images[0].convert("RGBA")
                            self.logger.info(f'üìê Original PDF dimensions: {original_img.size[0]}x{original_img.size[1]} pixels')
                        else:
                            self.logger.error(f'‚ùå Could not convert PDF to image - no images returned')
                            return self._create_social_formats_fallback(image_path, selected_formats)
                    except Exception as e:
                        self.logger.error(f'‚ùå PDF2IMAGE runtime error: {e}')
                        return self._create_social_formats_fallback(image_path, selected_formats)
                else:
                    self.logger.error(f'‚ùå PDF2IMAGE not available for PDF processing')
                    return self._create_social_formats_fallback(image_path, selected_formats)
            else:
                original_img = Image.open(image_path).convert("RGBA")
                self.logger.info(f'üìê Original image dimensions: {original_img.size[0]}x{original_img.size[1]} pixels')
        except Exception as e:
            self.logger.error(f'‚ùå Could not load image: {e}')
            return self._create_social_formats_fallback(image_path, selected_formats)
        
        # Get the background color from the original image
        background_color = self._extract_background_color(original_img)
        self.logger.info(f'üé® Extracted background color: {background_color}')
        
        # Determine which formats to create
        if selected_formats is None:
            # If no specific formats selected, create all (fallback behavior)
            formats_to_create = self.social_sizes
            self.logger.info(f'üìã No specific formats selected, creating all {len(formats_to_create)} formats')
        else:
            # Only create the selected formats
            formats_to_create = {}
            for platform, is_selected in selected_formats.items():
                if is_selected and platform in self.social_sizes:
                    formats_to_create[platform] = self.social_sizes[platform]
            
            self.logger.info(f'üìã Creating {len(formats_to_create)} selected formats: {list(formats_to_create.keys())}')
        
        if not formats_to_create:
            self.logger.warning(f'‚ö†Ô∏è No social formats selected or available')
            return {}
        
        out = {}
        formats_created = 0
        
        # Process each selected social media platform
        for platform_name, target_size in formats_to_create.items():
            self.logger.info(f'üì± Processing {platform_name}: {target_size[0]}x{target_size[1]} pixels')
            
            try:
                # Create the social format by resizing the original design to fit the target dimensions
                out_path = os.path.join(base_dir, f"{base_name}_{platform_name}.png")
                success = self._create_social_format_without_padding(
                    original_img, target_size, background_color, out_path
                )
                
                if success and os.path.exists(out_path):
                    out[platform_name] = out_path
                    file_size = os.path.getsize(out_path)
                    self.logger.info(f'‚úÖ {platform_name} created: {file_size:,} bytes')
                    formats_created += 1
                else:
                    self.logger.error(f'‚ùå Failed to create {platform_name}')
                        
            except Exception as e:
                self.logger.error(f'‚ùå Error processing {platform_name}: {e}')
        
        self.logger.info(f'üéâ Social media repurposing completed: {formats_created}/{len(formats_to_create)} formats created')
        
        # Ensure we return at least some result
        if not out:
            self.logger.warning(f'‚ö†Ô∏è No formats created, using fallback')
            return self._create_social_formats_fallback(image_path, selected_formats)
        
        return out
    
    def _extract_background_color(self, img):
        """Extract the dominant background color from the image"""
        try:
            # Convert to RGB for color analysis
            rgb_img = img.convert('RGB')
            
            # Get the corners and edges to determine background color
            width, height = rgb_img.size
            
            # Sample colors from corners and edges
            sample_points = [
                (0, 0),  # Top-left
                (width-1, 0),  # Top-right
                (0, height-1),  # Bottom-left
                (width-1, height-1),  # Bottom-right
                (width//2, 0),  # Top-center
                (width//2, height-1),  # Bottom-center
                (0, height//2),  # Left-center
                (width-1, height//2),  # Right-center
            ]
            
            colors = []
            for x, y in sample_points:
                try:
                    color = rgb_img.getpixel((x, y))
                    colors.append(color)
                except:
                    continue
            
            if not colors:
                return (255, 255, 255, 255)  # Default to white
            
            # Find the most common color (background)
            from collections import Counter
            color_counts = Counter(colors)
            background_color = color_counts.most_common(1)[0][0]
            
            # Convert to RGBA
            return background_color + (255,)
            
        except Exception as e:
            self.logger.warning(f'‚ö†Ô∏è Could not extract background color: {e}')
            return (255, 255, 255, 255)  # Default to white
    
    def _create_social_format_without_padding(self, original_img, target_size, background_color, out_path):
        """Create a social format by resizing the original design to fit target dimensions without padding"""
        try:
            # Calculate the scaling factor to fit the original design within the target dimensions
            original_width, original_height = original_img.size
            target_width, target_height = target_size
            
            # Calculate scaling factors for both dimensions
            scale_x = target_width / original_width
            scale_y = target_height / original_height
            
            # Use the smaller scaling factor to ensure the entire design fits
            scale = min(scale_x, scale_y)
            
            # Calculate new dimensions
            new_width = int(original_width * scale)
            new_height = int(original_height * scale)
            
            # Resize the original image
            resized_img = original_img.resize((new_width, new_height), Image.LANCZOS)
            
            # Create a new image with the target size and background color
            if len(background_color) == 3:
                # Convert RGB to RGBA
                bg_color = background_color + (255,)
            else:
                bg_color = background_color
            
            # Create background image
            background_img = Image.new("RGBA", target_size, bg_color)
            
            # Calculate position to center the resized image
            x = (target_width - new_width) // 2
            y = (target_height - new_height) // 2
            
            # Paste the resized image onto the background
            background_img.paste(resized_img, (x, y), resized_img)
            
            # Save the result
            background_img.save(out_path, "PNG")
            
            self.logger.info(f'üìê Resized from {original_width}x{original_height} to {new_width}x{new_height} (scale: {scale:.3f})')
            return True
            
        except Exception as e:
            self.logger.error(f'‚ùå Error creating social format: {e}')
            return False
    
    def _create_single_social_format_fallback(self, image_path, platform_name, target_size):
        """Create a single social format using simple fallback method that maintains original structure"""
        try:
            base_dir, base_name = _get_base(image_path)
            file_ext = os.path.splitext(image_path)[1].lower()
            
            # Load the original image
            if file_ext == '.pdf':
                if PDF2IMAGE_AVAILABLE:
                    try:
                        from pdf2image import convert_from_path
                        images = convert_from_path(image_path, first_page=0, last_page=0)
                        if images:
                            original_img = images[0].convert("RGBA")
                        else:
                            self.logger.error(f'‚ùå Could not convert PDF to image - no images returned')
                            return None
                    except Exception as e:
                        self.logger.error(f'‚ùå PDF2IMAGE runtime error: {e}')
                        return None
                else:
                    self.logger.error(f'‚ùå PDF2IMAGE not available for fallback processing')
                    return None
            else:
                original_img = Image.open(image_path).convert("RGBA")
            
            # Get the background color from the original image
            background_color = self._extract_background_color(original_img)
            
            # Create the social format
            out_path = os.path.join(base_dir, f"{base_name}_{platform_name}.png")
            success = self._create_social_format_without_padding(
                original_img, target_size, background_color, out_path
            )
            
            if success:
                return out_path
            else:
                return None
                
        except Exception as e:
            self.logger.error(f'‚ùå Fallback failed for {platform_name}: {e}')
            return None
    
    def _create_social_formats_fallback(self, image_path, selected_formats=None):
        """Fallback method that maintains the exact structure and content of the original design"""
        self.logger.info(f'üìù Using fallback social media processing for: {os.path.basename(image_path)}')
        
        base_dir, base_name = _get_base(image_path)
        file_ext = os.path.splitext(image_path)[1].lower()
        
        # Load the original image
        try:
            if file_ext == '.pdf':
                if PDF2IMAGE_AVAILABLE:
                    self.logger.info(f'üìÑ Converting PDF to image for fallback processing...')
                    try:
                        from pdf2image import convert_from_path
                        images = convert_from_path(image_path, first_page=0, last_page=0)
                        if images:
                            original_img = images[0].convert("RGBA")
                            self.logger.info(f'‚úÖ PDF converted successfully: {original_img.size}')
                        else:
                            self.logger.error(f'‚ùå Could not convert PDF to image - no images returned')
                            return {}
                    except Exception as e:
                        self.logger.error(f'‚ùå PDF2IMAGE runtime error: {e}')
                        return {}
                else:
                    self.logger.error(f'‚ùå PDF2IMAGE not available for fallback processing')
                    return {}
            else:
                original_img = Image.open(image_path).convert("RGBA")
        except Exception as e:
            self.logger.error(f'‚ùå Could not open file for fallback processing: {e}')
            import traceback
            self.logger.error(f'‚ùå Traceback: {traceback.format_exc()}')
            return {}
        
        # Get the background color from the original image
        background_color = self._extract_background_color(original_img)
        self.logger.info(f'üé® Extracted background color: {background_color}')
        
        # Determine which formats to create
        if selected_formats is None:
            # If no specific formats selected, create all (fallback behavior)
            formats_to_create = self.social_sizes
            self.logger.info(f'üìã No specific formats selected, creating all {len(formats_to_create)} formats')
        else:
            # Only create the selected formats
            formats_to_create = {}
            for platform, is_selected in selected_formats.items():
                if is_selected and platform in self.social_sizes:
                    formats_to_create[platform] = self.social_sizes[platform]
            
            self.logger.info(f'üìã Creating {len(formats_to_create)} selected formats: {list(formats_to_create.keys())}')
        
        if not formats_to_create:
            self.logger.warning(f'‚ö†Ô∏è No social formats selected or available')
            return {}
        
        self.logger.info(f'üìê Original image dimensions: {original_img.size[0]}x{original_img.size[1]} pixels')
        self.logger.info(f'üìã Available social formats: {len(formats_to_create)} platforms')
        
        out = {}
        formats_created = 0
        
        for name, size in formats_to_create.items():
            self.logger.info(f'üì± Processing {name}: {size[0]}x{size[1]} pixels')
            
            try:
                out_path = os.path.join(base_dir, f"{base_name}_{name}.png")
                success = self._create_social_format_without_padding(
                    original_img, size, background_color, out_path
                )
                
                if success and os.path.exists(out_path):
                    out[name] = out_path
                    file_size = os.path.getsize(out_path)
                    self.logger.info(f'‚úÖ {name} created: {file_size:,} bytes')
                    formats_created += 1
                else:
                    self.logger.error(f'‚ùå Failed to create {name}')
                    
            except Exception as e:
                self.logger.error(f'‚ùå Error processing {name}: {e}')
        
        self.logger.info(f'üéâ Fallback social media processing completed: {formats_created}/{len(formats_to_create)} formats created')
        return out

    def _create_contour_cutline(self, image_path):
        """Create clean contour cutline with background-aware edge detection for complete shapes"""
        self.logger.info(f'‚úÇÔ∏è Starting background-aware edge detection for: {os.path.basename(image_path)}')
        
        base_dir, base_name = _get_base(image_path)
        magenta_rgb = (255, 0, 255)  # Pink/Magenta for spot color
        magenta_hex = '#FF00FF'
        
        if cv2 is None:
            raise ImportError("OpenCV is required for contour cutline.")
        
        self.logger.info('üì∏ Loading image for contour cutline processing...')
        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)
        if img is None:
            raise ValueError(f"Could not load image: {image_path}")
        
        self.logger.info(f'üìê Image dimensions: {img.shape[1]}x{img.shape[0]} pixels')
        
        # Fix: Convert 16-bit images to 8-bit for OpenCV compatibility
        if img.dtype == np.uint16:
            self.logger.info('üîÑ Converting 16-bit image to 8-bit for OpenCV compatibility...')
            img = (img / 256).astype(np.uint8)
        
        # Handle alpha channel if present
        if img.shape[-1] == 4:
            self.logger.info('üé≠ Processing image with alpha channel...')
            alpha = img[:, :, 3] / 255.0
            rgb = img[:, :, :3].astype(float)
            white_bg = np.ones_like(rgb) * 255
            img = (rgb * alpha[:, :, np.newaxis] + white_bg * (1 - alpha[:, :, np.newaxis])).astype(np.uint8)
        else:
            img = img[:, :, :3]
        
        # Create full color mask (preserve original colors)
        self.logger.info('üé® Creating full color mask...')
        full_color_mask = img.copy()
        
        # ENHANCED BACKGROUND-AWARE DETECTION WITH PARALLEL SUBTASKS
        self.logger.info('üé® Performing background-aware contour detection with parallel subtasks...')
        
        # Step 1: Analyze background color (parallel with other operations)
        h, w = img.shape[:2]
        
        # Sample background color from corners and edges
        corner_samples = [
            img[0:20, 0:20],  # Top-left
            img[0:20, w-20:w],  # Top-right
            img[h-20:h, 0:20],  # Bottom-left
            img[h-20:h, w-20:w]  # Bottom-right
        ]
        
        background_colors = []
        for sample in corner_samples:
            avg_color = np.mean(sample.reshape(-1, 3), axis=0)
            background_colors.append(avg_color)
        
        # Use the most common background color
        background_color = np.mean(background_colors, axis=0)
        self.logger.info(f'üé® Detected background color: RGB({background_color[2]:.0f}, {background_color[1]:.0f}, {background_color[0]:.0f})')
        
        # Step 2: Create mask based on color difference from background
        self.logger.info('üéØ Creating color difference mask...')
        
        # Calculate color distance from background
        color_diff = np.sqrt(np.sum((img.astype(float) - background_color) ** 2, axis=2))
        
        # Create mask where pixels are significantly different from background
        # Use adaptive threshold based on the image
        threshold = np.std(color_diff) * 1.5  # Dynamic threshold
        color_mask = (color_diff > threshold).astype(np.uint8) * 255
        
        self.logger.info(f'üéØ Using color difference threshold: {threshold:.1f}')
        
        # Step 3: Clean up the mask
        self.logger.info('üßπ Cleaning up color mask...')
        
        # Apply slight morphological operations to clean up noise
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        color_mask = cv2.morphologyEx(color_mask, cv2.MORPH_CLOSE, kernel)  # Fill small gaps
        color_mask = cv2.morphologyEx(color_mask, cv2.MORPH_OPEN, kernel)   # Remove small noise
        
        # Step 4: Find contours using RETR_TREE to get both outer and inner contours
        self.logger.info('üéØ Finding all contours (outer + inner)...')
        contours, hierarchy = cv2.findContours(color_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
        
        self.logger.info(f'üìä Found {len(contours)} total contours from color analysis')
        
        # Step 5: Filter and classify contours
        valid_contours = []
        
        for i, contour in enumerate(contours):
            area = cv2.contourArea(contour)
            
            # Filter by area - keep meaningful contours
            if area > 200:  # Minimum area for real shapes
                # Check if it's an outer contour (no parent) or inner contour (has parent)
                has_parent = hierarchy[0][i][3] >= 0
                
                if has_parent:
                    self.logger.info(f'‚úÖ Added inner contour {i}: area={area:.1f} (hole)')
                else:
                    self.logger.info(f'‚úÖ Added outer contour {i}: area={area:.1f} (shape)')
                
                valid_contours.append(contour)
        
        # Step 6: Also try traditional edge detection for any missed edges (parallel operation)
        self.logger.info('üîç Adding traditional edge detection as backup...')
        
        # Convert to grayscale and apply Canny
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        blurred = cv2.GaussianBlur(gray, (3, 3), 0)
        edges = cv2.Canny(blurred, 30, 100, apertureSize=3, L2gradient=True)
        
        # Find edge contours
        edge_contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # Add any significant edge contours that weren't found by color analysis
        for contour in edge_contours:
            area = cv2.contourArea(contour)
            if area > 500:  # Only larger edge contours
                # Check if this contour is already covered by color analysis
                is_duplicate = False
                for existing_contour in valid_contours:
                    similarity = cv2.matchShapes(contour, existing_contour, cv2.CONTOURS_MATCH_I1, 0.0)
                    if similarity < 0.1:  # Very similar
                        is_duplicate = True
                        break
                
                if not is_duplicate:
                    valid_contours.append(contour)
                    self.logger.info(f'‚úÖ Added edge contour: area={area:.1f} (edge backup)')
        
        # BACKGROUND DETECTION (parallel operation)
        self.logger.info('üé® Detecting background for contouring...')
        background_contour = self._detect_background_contour(img)
        
        # Add background contour if detected
        if background_contour is not None:
            valid_contours.append(background_contour)
            self.logger.info('‚úÖ Added background contour')
        
        background_count = 1 if background_contour is not None else 0
        inner_count = sum(1 for i, _ in enumerate(contours) if hierarchy[0][i][3] >= 0 and cv2.contourArea(contours[i]) > 200)
        outer_count = len(valid_contours) - background_count - inner_count
        
        self.logger.info(f'üéØ Final contour count: {len(valid_contours)} ({outer_count} outer + {inner_count} inner + {background_count} background)')
        
        # PARALLEL FILE GENERATION
        self.logger.info('ü©∑ Creating output files in parallel...')
        
        # Create output images with MAGENTA color
        outline_mask = np.zeros(img.shape, dtype=np.uint8)  # 3-channel for color
        
        # Draw all contours in MAGENTA with thin lines
        for contour in valid_contours:
            cv2.drawContours(outline_mask, [contour], -1, magenta_rgb, 1)  # 1-pixel thickness for clean edges
        
        # Save output files (parallel operations)
        full_color_path = os.path.join(base_dir, f'{base_name}_contour_cutline_fullcolor.png')
        outline_path = os.path.join(base_dir, f'{base_name}_contour_cutline_outline.png')
        
        self.logger.info(f'üíæ Saving full color mask to: {full_color_path}')
        cv2.imwrite(full_color_path, full_color_mask)
        
        self.logger.info(f'üíæ Saving magenta outline mask to: {outline_path}')
        cv2.imwrite(outline_path, outline_mask)
        
        # Create SVG output with layered approach (original image + spot color mask)
        self.logger.info('üìê Creating layered SVG with original image and spot color mask...')
        svg_path = os.path.join(base_dir, f'{base_name}_contour_cutline_combined.svg')
        
        # Convert the original image to base64 for embedding in SVG
        import base64
        from io import BytesIO
        from PIL import Image
        
        # Convert OpenCV image to PIL and save to base64
        pil_img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        img_buffer = BytesIO()
        pil_img.save(img_buffer, format='PNG')
        img_base64 = base64.b64encode(img_buffer.getvalue()).decode('utf-8')
        
        # Create layered SVG with original image as background and spot color contours on top
        svg_content = f'''<?xml version="1.0" encoding="UTF-8"?>
<svg width="{img.shape[1]}" height="{img.shape[0]}" xmlns="http://www.w3.org/2000/svg">
  <defs>
    <style>
      .contour {{ fill: none; stroke: {magenta_hex}; stroke-width: 2; stroke-linecap: round; stroke-linejoin: round; }}
      .background-image {{ opacity: 1; }}
      .spot-color-layer {{ opacity: 1; }}
    </style>
  </defs>
  
  <!-- Background Layer: Original Raster Image -->
  <g class="background-image">
    <image href="data:image/png;base64,{img_base64}" width="{img.shape[1]}" height="{img.shape[0]}" x="0" y="0"/>
  </g>
  
  <!-- Spot Color Layer: Contour Cutlines -->
  <g class="spot-color-layer">'''
        
        for i, contour in enumerate(valid_contours):
            # Convert contour to SVG path
            points = contour.reshape(-1, 2)
            if len(points) > 2:
                path_data = f"M {points[0][0]} {points[0][1]}"
                for point in points[1:]:
                    path_data += f" L {point[0]} {point[1]}"
                path_data += " Z"
                
                svg_content += f'\n    <path class="contour" d="{path_data}"/>'
        
        svg_content += '''
  </g>
</svg>'''
        
        with open(svg_path, 'w') as f:
            f.write(svg_content)
        
        self.logger.info(f'üíæ Saving layered SVG to: {svg_path}')
        
        # Create PDF output with layered approach
        self.logger.info('üìÑ Creating layered PDF with original image and spot color mask...')
        pdf_path = os.path.join(base_dir, f'{base_name}_contour_cutline_combined.pdf')
        
        try:
            import cairosvg
            # Create PDF with high DPI for print quality
            cairosvg.svg2pdf(url=svg_path, write_to=pdf_path, dpi=300)
            self.logger.info(f'üíæ Layered PDF saved to: {pdf_path}')
        except Exception as e:
            self.logger.warning(f'‚ö†Ô∏è PDF generation failed: {e}')
            pdf_path = None
        
        # Prepare outputs dictionary
        outputs = {
            'full_color_mask': full_color_path,
            'pink_outline_mask': outline_path,
            'combined_svg': svg_path
        }
        
        if pdf_path:
            outputs['combined_pdf'] = pdf_path
        
        return {
            'success': True,
            'outputs': outputs,
            'contour_count': len(valid_contours),
            'files_generated': len(outputs),
            'background_detected': background_contour is not None,
            'message': f'Background-aware contour cutline created with {len(valid_contours)} contours ({outer_count} outer + {inner_count} inner)'
        }

    def _detect_background_contour(self, img):
        """Detect colored backgrounds and create contour for them"""
        self.logger.info('üé® Analyzing background for contouring...')
        
        # Convert to HSV for better color analysis
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        
        # Get image dimensions
        height, width = img.shape[:2]
        
        # Sample colors from corners and edges to detect background
        corner_samples = []
        edge_samples = []
        
        # Sample corners
        corner_samples.extend([
            img[0, 0], img[0, width-1], img[height-1, 0], img[height-1, width-1]
        ])
        
        # Sample edges (every 10th pixel)
        for i in range(0, width, 10):
            edge_samples.extend([img[0, i], img[height-1, i]])
        for i in range(0, height, 10):
            edge_samples.extend([img[i, 0], img[i, width-1]])
        
        # Analyze background color
        all_samples = np.array(corner_samples + edge_samples)
        background_color = np.median(all_samples, axis=0)
        
        # Check if background is colored (not white or black)
        is_white = np.all(background_color > [200, 200, 200])
        is_black = np.all(background_color < [50, 50, 50])
        
        if not (is_white or is_black):
            self.logger.info(f'üé® Detected colored background: RGB{tuple(background_color.astype(int))}')
            
            # Create background contour (full image rectangle)
            background_contour = np.array([
                [[0, 0]],
                [[width, 0]],
                [[width, height]],
                [[0, height]]
            ], dtype=np.int32)
            
            return background_contour
        else:
            self.logger.info(f'üé® Background is white/black, no background contour needed')
            return None

    def _find_inner_contours(self, edges, img):
        """Find inner contours (holes) of letters and numbers"""
        self.logger.info('üîç Detecting inner contours for text elements...')
        
        # Use RETR_TREE to get hierarchy information
        contours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
        
        inner_contours = []
        image_area = img.shape[0] * img.shape[1]
        min_area = max(50, int(image_area * 0.0001))  # Balanced threshold
        
        for i, contour in enumerate(contours):
            area = cv2.contourArea(contour)
            
            # Skip very small contours
            if area < min_area:
                continue
            
            # Check if this is an inner contour (has a parent)
            if hierarchy[0][i][3] >= 0:  # Has a parent
                parent_idx = hierarchy[0][i][3]
                parent_area = cv2.contourArea(contours[parent_idx]) if parent_idx >= 0 else 0
                
                # Calculate relative size (inner contour should be smaller than parent)
                if parent_area > 0 and area < parent_area * 0.8:
                    
                    # Calculate contour properties
                    perimeter = cv2.arcLength(contour, True)
                    compactness = (perimeter * perimeter) / (4 * np.pi * area) if area > 0 else float('inf')
                    
                    # Calculate aspect ratio
                    x, y, w, h = cv2.boundingRect(contour)
                    aspect_ratio = w / h if h > 0 else 0
                    size_ratio = area / parent_area
                    
                    # BALANCED FILTERING FOR TEXT HOLES
                    # More selective criteria to avoid noise while detecting real text holes
                    
                    # Criterion 1: Must be reasonably compact (holes are usually compact)
                    if compactness > 50:  # Too irregular, likely noise
                        continue
                    
                    # Criterion 2: Reasonable aspect ratios for text holes
                    if aspect_ratio < 0.1 or aspect_ratio > 10:  # Too extreme
                        continue
                    
                    # Criterion 3: Size relative to parent (not too small, not too large)
                    if size_ratio < 0.02 or size_ratio > 0.6:  # Too small or too large
                        continue
                    
                    # Criterion 4: Minimum area for meaningful holes
                    if area < 100:  # Too small to be meaningful
                        continue
                    
                    # Criterion 5: Look for specific text hole characteristics
                    # Circular/oval holes (common in B, 0, 9)
                    is_circular_hole = (compactness < 25 and 0.3 < aspect_ratio < 3.0)
                    
                    # Rectangular holes (common in F, some letters)
                    is_rectangular_hole = (compactness < 20 and (aspect_ratio > 3.0 or aspect_ratio < 0.3))
                    
                    # Medium-sized holes (typical for text)
                    is_medium_hole = (100 < area < 50000 and compactness < 30)
                    
                    if is_circular_hole or is_rectangular_hole or is_medium_hole:
                        inner_contours.append(contour)
                        self.logger.info(f'‚úÖ Added inner contour {i}: area={area:.1f}, parent_area={parent_area:.1f}, compactness={compactness:.1f}, aspect_ratio={aspect_ratio:.2f}, size_ratio={size_ratio:.3f}')
        
        self.logger.info(f'üéØ Found {len(inner_contours)} valid inner contours')
        return inner_contours

    # ----------- Parallel Processing Methods -----------
    def process_logo_parallel(self, file_path, options=None):
        """Distributed parallel processing using Celery with robust fallback to direct execution"""
        if options is None:
            options = {}
        start_time = time.time()
        self.logger.info(f'üöÄ Starting distributed parallel processing (Celery) for: {os.path.basename(file_path)}')
        
        # Map option keys to LogoProcessor method names
        option_to_func = {
            'transparent_png': '_create_transparent_png',
            'black_version': '_create_black_version',
            'pdf_version': '_create_pdf_version',
            'webp_version': '_create_webp_version',
            'favicon': '_create_favicon',
            'email_header': '_create_email_header',
            'vector_trace': '_create_vector_trace',
            'full_color_vector_trace': '_create_full_color_vector_trace',
            'color_separations': '_create_color_separations',
            'distressed_effect': '_create_distressed_version',
            'halftone': '_create_halftone',
            'contour_cut': '_create_contour_cutline',
        }
        
        # Create task list
        tasks = []
        for opt, func_name in option_to_func.items():
            if options.get(opt, False):
                tasks.append((func_name, file_path, options))
        
        # Social media formats
        social_formats = options.get('social_formats', {})
        if any(social_formats.values()):
            tasks.append(('_create_social_formats', file_path, options))
        
        if not tasks:
            return {
                'success': False,
                'outputs': {},
                'message': 'No variations selected',
                'processing_time': 0
            }
        
        # Enhanced Celery availability check with fast failover
        celery_available = False
        self.logger.info(f'üîç Checking Celery availability...')
        
        try:
            from utils.celery_worker import celery_app, run_logo_task
            
            # Quick Redis connection test with short timeout
            self.logger.info('üì° Testing Redis connection...')
            broker_connection = celery_app.broker_connection()
            broker_connection.ensure_connection(max_retries=2, interval_start=0.1, interval_step=0.1, interval_max=0.5)
            broker_connection.release()
            
            # Test if Celery worker is active
            self.logger.info('üîç Checking for active Celery workers...')
            inspect = celery_app.control.inspect()
            active_workers = inspect.active()
            
            if active_workers:
                celery_available = True
                worker_count = len(active_workers)
                self.logger.info(f'‚úÖ Celery available with {worker_count} active worker(s)')
            else:
                self.logger.warning('‚ö†Ô∏è  No active Celery workers found, falling back to direct execution')
                
        except Exception as celery_error:
            self.logger.warning(f'‚ö†Ô∏è  Celery not available: {str(celery_error)[:100]}...')
        
        # Execute with Celery if available, otherwise use direct execution
        if celery_available:
            return self._execute_with_celery(tasks, file_path, options, start_time)
        else:
            return self._execute_direct(tasks, file_path, options, start_time)
    
    def _execute_with_celery(self, tasks, file_path, options, start_time):
        """Execute tasks using Celery with ultra-fast parallel processing for 20-second target"""
        from utils.celery_worker import celery_app, run_ultra_fast_task, run_vector_task, run_social_task
        
        self.logger.info(f'‚ö° Submitting {len(tasks)} tasks to ultra-fast Celery workers...')
        
        # Categorize tasks by type for optimal queue assignment
        vector_tasks = []
        social_tasks = []
        ultra_fast_tasks = []
        
        for func_name, fpath, opts in tasks:
            if func_name in ['_create_vector_trace', '_create_full_color_vector_trace', '_create_color_separations']:
                vector_tasks.append((func_name, fpath, opts))
            elif func_name == '_create_social_formats':
                social_tasks.append((func_name, fpath, opts))
            else:
                ultra_fast_tasks.append((func_name, fpath, opts))
        
        # Submit tasks to appropriate queues for ultra-fast parallel processing
        async_results = []
        
        # Submit ultra-fast tasks (highest priority, fastest processing)
        for func_name, fpath, opts in ultra_fast_tasks:
            try:
                async_result = run_ultra_fast_task.delay(func_name, fpath, opts)
                async_results.append((func_name, async_result))
                self.logger.info(f'‚ö° Submitted ultra-fast task: {func_name}')
            except Exception as e:
                self.logger.error(f'‚ùå Failed to submit ultra-fast task {func_name}: {str(e)}')
        
        # Submit vector tasks
        for func_name, fpath, opts in vector_tasks:
            try:
                async_result = run_vector_task.delay(func_name, fpath, opts)
                async_results.append((func_name, async_result))
                self.logger.info(f'‚úÖ Submitted vector task: {func_name}')
            except Exception as e:
                self.logger.error(f'‚ùå Failed to submit vector task {func_name}: {str(e)}')
        
        # Submit social tasks
        for func_name, fpath, opts in social_tasks:
            try:
                async_result = run_social_task.delay(func_name, fpath, opts)
                async_results.append((func_name, async_result))
                self.logger.info(f'‚úÖ Submitted social task: {func_name}')
            except Exception as e:
                self.logger.error(f'‚ùå Failed to submit social task {func_name}: {str(e)}')
        
        # Wait for all tasks to complete with increased timeout
        outputs = {}
        messages = []
        completed = 0
        total_tasks = len(async_results)
        
        self.logger.info(f'‚ö° Waiting for {total_tasks} tasks to complete in ultra-fast parallel mode...')
        
        # Increased timeout for 20-second target
        timeout_per_task = 20  # 20 seconds per task maximum
        
        for func_name, async_result in async_results:
            try:
                self.logger.info(f'‚ö° Waiting for {func_name} ({timeout_per_task}s timeout)...')
                result = async_result.get(timeout=timeout_per_task)
                
                # Special handling for social formats - check if result is empty
                if func_name == '_create_social_formats' and (not result or (isinstance(result, dict) and len(result) == 0)):
                    self.logger.warning(f'‚ö†Ô∏è Celery returned empty result for {func_name}, trying direct execution...')
                    try:
                        # Fall back to direct execution for social formats
                        direct_result = self._execute_single_task_direct(func_name, file_path, options)
                        if direct_result and isinstance(direct_result, dict) and len(direct_result) > 0:
                            result = direct_result
                            messages.append(f'{func_name} completed (direct fallback)')
                            self.logger.info(f'‚úÖ Direct fallback succeeded: {func_name}')
                        else:
                            messages.append(f'{func_name} failed - empty result from both Celery and direct')
                            self.logger.error(f'‚ùå Direct fallback also failed: {func_name}')
                            continue
                    except Exception as e:
                        messages.append(f'{func_name} failed - direct fallback error: {str(e)}')
                        self.logger.error(f'‚ùå Direct fallback error for {func_name}: {str(e)}')
                        continue
                # Special handling for vector trace - check if result is empty or None
                elif func_name in ['_create_vector_trace', '_create_full_color_vector_trace'] and (not result or (isinstance(result, dict) and len(result) == 0)):
                    self.logger.warning(f'‚ö†Ô∏è Celery returned empty result for {func_name}, trying direct execution...')
                    try:
                        # Fall back to direct execution for vector trace
                        direct_result = self._execute_single_task_direct(func_name, file_path, options)
                        if direct_result and isinstance(direct_result, dict) and len(direct_result) > 0:
                            result = direct_result
                            messages.append(f'{func_name} completed (direct fallback)')
                            self.logger.info(f'‚úÖ Direct fallback succeeded: {func_name}')
                        else:
                            messages.append(f'{func_name} failed - empty result from both Celery and direct')
                            self.logger.error(f'‚ùå Direct fallback also failed: {func_name}')
                            continue
                    except Exception as e:
                        messages.append(f'{func_name} failed - direct fallback error: {str(e)}')
                        self.logger.error(f'‚ùå Direct fallback error for {func_name}: {str(e)}')
                        continue
                else:
                    # Normal successful completion
                    outputs[func_name] = result
                    completed += 1
                    messages.append(f'{func_name} completed (Celery)')
                    self.logger.info(f'‚úÖ Celery task completed: {func_name} ({completed}/{total_tasks})')
                    
            except Exception as e:
                self.logger.error(f'‚ùå {func_name} failed: {str(e)}')
                self.logger.error(f'‚ùå Exception type: {type(e).__name__}')
                self.logger.error(f'‚ùå Traceback: {e}')
                
                # Attempt direct execution fallback
                self.logger.info(f'üîÑ Attempting direct execution fallback for {func_name}...')
                try:
                    direct_result = self._execute_single_task_direct(func_name, file_path, options)
                    if direct_result:
                        outputs[func_name] = direct_result
                        completed += 1
                        messages.append(f'{func_name} completed (direct fallback)')
                        self.logger.info(f'‚úÖ Direct fallback succeeded: {func_name}')
                    else:
                        messages.append(f'{func_name} failed - no result from direct execution')
                        self.logger.error(f'‚ùå Direct fallback failed: {func_name} - no result')
                except Exception as fallback_error:
                    messages.append(f'{func_name} failed: {str(fallback_error)}')
                    self.logger.error(f'‚ùå Direct fallback error for {func_name}: {str(fallback_error)}')
        
        processing_time = time.time() - start_time
        self.logger.info(f'üèÅ Celery processing completed in {processing_time:.2f}s')
        
        return {
            'success': len(outputs) > 0,
            'outputs': outputs,
            'message': '; '.join(messages),
            'total_outputs': len(outputs),
            'processing_time': processing_time,
            'parallel': True,
            'tasks_processed': total_tasks,
            'completed_count': completed,
            'success_rate': f'{completed/total_tasks*100:.1f}%' if total_tasks > 0 else '0%',
            'execution_method': 'celery',
            'fallback_used': completed < total_tasks
        }
    
    def _execute_direct(self, tasks, file_path, options, start_time):
        """Execute tasks directly without Celery"""
        self.logger.info(f'üîÑ Executing {len(tasks)} tasks directly (sequential)...')
        
        outputs = {}
        messages = []
        completed = 0
        
        for func_name, fpath, opts in tasks:
            try:
                self.logger.info(f'üîÑ Processing {func_name}...')
                direct_result = self._execute_single_task_direct(func_name, fpath, opts)
                
                if direct_result:
                    outputs[func_name] = direct_result
                    completed += 1
                    messages.append(f'{func_name} completed (direct)')
                    self.logger.info(f'‚úÖ Direct execution: {func_name} ({completed}/{len(tasks)})')
                else:
                    messages.append(f'{func_name} failed - no result')
                    self.logger.warning(f'‚ùå Direct execution failed: {func_name} - no result')
                    
            except Exception as e:
                self.logger.error(f'‚ùå Direct execution failed for {func_name}: {str(e)}')
                messages.append(f'{func_name} failed: {str(e)}')
        
        processing_time = time.time() - start_time
        self.logger.info(f'üèÅ Direct execution completed in {processing_time:.2f}s')
        
        return {
            'success': len(outputs) > 0,
            'outputs': outputs,
            'message': '; '.join(messages),
            'total_outputs': len(outputs),
            'processing_time': processing_time,
            'parallel': False,
            'tasks_processed': len(tasks),
            'completed_count': completed,
            'success_rate': f'{completed/len(tasks)*100:.1f}%' if len(tasks) > 0 else '0%',
            'execution_method': 'direct',
            'fallback_used': True
        }
    
    def _execute_single_task_direct(self, func_name, file_path, options):
        """Execute a single task directly"""
        func = getattr(self, func_name)
        if func_name == '_create_social_formats':
            return func(file_path, options.get('social_formats', {}))
        else:
            return func(file_path)

    def update_progress(self, task_name: str, progress: float, message: str = ''):
        """Update progress for parallel processing"""
        pass  # Simplified for speed
    
    def get_progress(self) -> dict:
        """Get current progress data"""
        return {}  # Simplified for speed
    
    def set_progress_callback(self, callback: Callable):
        """Set a callback function for progress updates"""
        pass  # Simplified for speed
    
    def get_performance_stats(self) -> dict:
        """Get performance statistics"""
        return {
            'parallel_enabled': True,
            'max_workers': 8,
            'cpu_count': os.cpu_count()
        }
    
    def _get_memory_usage(self) -> dict:
        """Get current memory usage"""
        return {'status': 'available'}  # Simplified for speed
    
    def optimize_worker_count(self, task_count: int) -> int:
        """Optimize worker count for speed"""
        cpu_count = os.cpu_count() or 4
        return min(task_count, cpu_count * 2, 8)  # Max 8 workers for speed
    
    def get_task_priority(self, task_name: str) -> int:
        """Get priority for task scheduling"""
        return 1  # All tasks have same priority for speed

    # ----------- Main Processing -----------
    def process_logo(self, file_path, options=None):
        """Main logo processing method - ALWAYS uses parallel processing for maximum performance"""
        if options is None:
            options = {}
        
        self.logger.info(f"üöÄ Starting logo processing for: {os.path.basename(file_path)}")
        self.logger.info(f"üìã Processing options: {options}")
        
        # Always use parallel processing for better performance
        self.logger.info('‚ö° Using parallel processing for maximum performance')
        return self.process_logo_parallel(file_path, options)
    
    def _should_use_parallel(self, options):
        """Determine if parallel processing should be used"""
        # Count how many variations are requested
        variation_count = 0
        
        # Basic variations
        if options.get('transparent_png', False): variation_count += 1
        if options.get('black_version', False): variation_count += 1
        if options.get('pdf_version', False): variation_count += 1
        if options.get('webp_version', False): variation_count += 1
        if options.get('favicon', False): variation_count += 1
        if options.get('email_header', False): variation_count += 1
        
        # Effects variations
        if options.get('vector_trace', False): variation_count += 1
        if options.get('full_color_vector_trace', False): variation_count += 1
        if options.get('color_separations', False): variation_count += 1
        if options.get('distressed_effect', False): variation_count += 1
        if options.get('halftone', False): variation_count += 1
        if options.get('contour_cut', False): variation_count += 1
        
        # Social media formats
        social_formats = options.get('social_formats', {})
        if any(social_formats.values()): variation_count += 1
        
        # Use parallel processing if more than 1 variation is requested
        return variation_count > 1
    
    def _process_logo_sequential(self, file_path, options=None):
        """Original sequential processing method - kept for backward compatibility"""
        if options is None:
            options = {}
        
        start_time = time.time()
        outputs = {}
        success = True
        messages = []
        
        try:
            # Handle vector trace option
            vector_result = None
            if options.get('vector_trace', False):
                self.logger.info("Processing vector trace...")
                vector_result = self.generate_vector_trace(file_path, options)
                
                if vector_result.get('status') == 'success' and vector_result.get('output_paths'):
                    output_paths = vector_result['output_paths']
                    if output_paths.get('svg'):
                        outputs['vector_trace_svg'] = output_paths['svg']
                    if output_paths.get('pdf'):
                        outputs['vector_trace_pdf'] = output_paths['pdf']
                    if output_paths.get('eps'):
                        outputs['vector_trace_eps'] = output_paths['eps']
                    messages.append("Vector trace completed successfully")
                else:
                    success = False
                    messages.append(f"Vector trace failed: {vector_result.get('message', 'Unknown error')}")
            
            # Handle other options (transparent, black, etc.) by calling existing methods
            base_dir, base_name = _get_base(file_path)
            
            if options.get('transparent_png', False):
                try:
                    result = self._create_transparent_png(file_path)
                    outputs['transparent_png'] = result
                    messages.append("Transparent PNG created")
                except Exception as e:
                    self.logger.error(f"Transparent PNG creation failed: {e}")
                    messages.append(f"Transparent PNG failed: {str(e)}")
            
            if options.get('black_version', False):
                try:
                    result = self._create_black_version(file_path)
                    outputs['black_version'] = result
                    messages.append("Black version created")
                except Exception as e:
                    self.logger.error(f"Black version creation failed: {e}")
                    messages.append(f"Black version failed: {str(e)}")
            
            if options.get('pdf_version', False):
                try:
                    result = self._create_pdf_version(file_path)
                    outputs['pdf_version'] = result.get('pdf') if isinstance(result, dict) else result
                    messages.append("PDF version created")
                except Exception as e:
                    self.logger.error(f"PDF version creation failed: {e}")
                    messages.append(f"PDF version failed: {str(e)}")
            
            if options.get('webp_version', False):
                try:
                    result = self._create_webp_version(file_path)
                    outputs['webp_version'] = result.get('webp') if isinstance(result, dict) else result
                    messages.append("WebP version created")
                except Exception as e:
                    self.logger.error(f"WebP version creation failed: {e}")
                    messages.append(f"WebP version failed: {str(e)}")
            
            if options.get('favicon', False):
                try:
                    result = self._create_favicon(file_path)
                    outputs['favicon'] = result.get('ico') if isinstance(result, dict) else result
                    messages.append("Favicon created")
                except Exception as e:
                    self.logger.error(f"Favicon creation failed: {e}")
                    messages.append(f"Favicon failed: {str(e)}")
            
            if options.get('email_header', False):
                try:
                    result = self._create_email_header(file_path)
                    outputs['email_header'] = result.get('png') if isinstance(result, dict) else result
                    messages.append("Email header created")
                except Exception as e:
                    self.logger.error(f"Email header creation failed: {e}")
                    messages.append(f"Email header failed: {str(e)}")
            
            if options.get('full_color_vector_trace', False):
                try:
                    result = self._create_full_color_vector_trace(file_path)
                    outputs['full_color_vector_trace'] = result
                    messages.append("Full color vector trace created")
                except Exception as e:
                    self.logger.error(f"Full color vector trace creation failed: {e}")
                    messages.append(f"Full color vector trace failed: {str(e)}")
            
            if options.get('color_separations', False):
                try:
                    result = self._create_color_separations(file_path)
                    outputs['color_separations'] = result
                    messages.append("Color separations created")
                except Exception as e:
                    self.logger.error(f"Color separations creation failed: {e}")
                    messages.append(f"Color separations failed: {str(e)}")
            
            if options.get('distressed_effect', False):
                try:
                    result = self._create_distressed_version(file_path)
                    outputs['distressed_effect'] = result
                    messages.append("Distressed effect created")
                except Exception as e:
                    self.logger.error(f"Distressed effect creation failed: {e}")
                    messages.append(f"Distressed effect failed: {str(e)}")
            
            if options.get('halftone', False):
                try:
                    result = self._create_halftone(file_path)
                    outputs['halftone'] = result
                    messages.append("Halftone effect created")
                except Exception as e:
                    self.logger.error(f"Halftone effect creation failed: {e}")
                    messages.append(f"Halftone effect failed: {str(e)}")
            
            if options.get('contour_cut', False):
                try:
                    result = self._create_contour_cutline(file_path)
                    outputs['contour_cut'] = result
                    messages.append("Contour cut created")
                except Exception as e:
                    self.logger.error(f"Contour cut creation failed: {e}")
                    messages.append(f"Contour cut failed: {str(e)}")
            
            social_formats = options.get('social_formats', {})
            if any(social_formats.values()):
                try:
                    result = self._create_social_formats(file_path, social_formats)
                    if result is not None:  # Check for None instead of truthiness
                        outputs['social_formats'] = result
                        messages.append("Social formats created")
                    else:
                        success = False
                        messages.append("Social formats failed - no result returned")
                except Exception as e:
                    self.logger.error(f"Social formats creation failed: {e}")
                    messages.append(f"Social formats failed: {str(e)}")
        
        except Exception as e:
            self.logger.error(f"Sequential processing failed: {e}")
            success = False
            messages.append(f"Processing failed: {str(e)}")
        
        processing_time = time.time() - start_time
        self.logger.info(f'Sequential processing completed in {processing_time:.2f}s')
        
        return {
            'success': success and len(outputs) > 0,
            'outputs': outputs,
            'message': '; '.join(messages) if messages else 'No operations requested',
            'total_outputs': len(outputs),
            'processing_time': processing_time,
            'parallel': False,
            'workers_used': 1
        }
    
    def generate_vector_trace(self, file_path, options=None):
        """High-quality multi-color vector tracing using vtracer's native RGBA pixel processing"""
        if not VTRACER_AVAILABLE:
            self.logger.error("vtracer is not available. Please install it with: pip install vtracer")
            return {
                'status': 'error',
                'message': 'vtracer is not available. Please install it with: pip install vtracer'
            }
        
        base_dir, base_name = _get_base(file_path)
        
        # Load image with maximum quality
        img = Image.open(file_path).convert("RGBA")
        img_array = np.array(img)
        
        # Strategy 1: Upscale for maximum detail preservation
        upscale_factor = 8 if max(img.size) < 200 else 4 if max(img.size) < 400 else 2 if max(img.size) < 800 else 1
        
        if upscale_factor > 1:
            upscaled_img = img.resize((img.width * upscale_factor, img.height * upscale_factor), Image.Resampling.LANCZOS)
            working_array = np.array(upscaled_img)
            working_size = (upscaled_img.width, upscaled_img.height)
        else:
            working_array = img_array
            working_size = img.size
        
        # Strategy 2: Use vtracer's native RGBA pixel processing
        # Convert numpy array to the format vtracer expects (list of RGBA tuples)
        # Convert numpy uint8 to Python int to avoid type issues
        rgba_pixels = [tuple(int(val) for val in row) for row in working_array.reshape(-1, 4)]
        
        print(f"DEBUG: Image size: {working_size}, pixels: {len(rgba_pixels)}, upscale: {upscale_factor}x")
        print(f"DEBUG: First pixel: {rgba_pixels[0]}, type: {type(rgba_pixels[0][0])}")
        
        # Use vtracer with FULL COLOR multi-color processing
        svg_str = vtracer.convert_pixels_to_svg(
            rgba_pixels,
            working_size,
            colormode="color",  # FULL COLOR MODE - not binary!
            hierarchical="stacked",  # Better for complex logos with holes
            mode="spline",  # Smooth curves
            filter_speckle=0,  # No filtering - preserve all details
            color_precision=6,  # High color precision for grouping
            layer_difference=16,  # Low threshold for layer separation
            corner_threshold=15,  # Detect more corners
            length_threshold=0.5,  # Preserve small details
            max_iterations=30,  # Maximum quality
            splice_threshold=15,  # More path splitting
            path_precision=5  # Maximum precision
        )
        
        # Scale down paths if we upscaled
        if upscale_factor > 1:
            # Parse and scale down the SVG paths
            import re
            
            def scale_path_data(match):
                path_data = match.group(1)
                # Scale down all numeric values in the path
                def scale_number(num_match):
                    return str(float(num_match.group(0)) / upscale_factor)
                
                scaled_path = re.sub(r'-?\d+\.?\d*', scale_number, path_data)
                return f'd="{scaled_path}"'
            
            def scale_dimension(match):
                return str(float(match.group(0)) / upscale_factor)
            
            # Scale down the SVG
            svg_str = re.sub(r'd="([^"]*)"', scale_path_data, svg_str)
            svg_str = re.sub(r'width="([^"]*)"', lambda m: f'width="{float(m.group(1)) / upscale_factor}"', svg_str)
            svg_str = re.sub(r'height="([^"]*)"', lambda m: f'height="{float(m.group(1)) / upscale_factor}"', svg_str)
            svg_str = re.sub(r'viewBox="([^"]*)"', lambda m: f'viewBox="{" ".join([str(float(x) / upscale_factor) for x in m.group(1).split()])}"', svg_str)
        
        # Save SVG
        svg_path = os.path.join(base_dir, f"{base_name}_vector.svg")
        with open(svg_path, "w", encoding="utf-8") as f:
            f.write(svg_str)
        
        # Save PDF with maximum quality
        pdf_path = os.path.join(base_dir, f"{base_name}_vector.pdf")
        try:
            cairosvg.svg2pdf(bytestring=svg_str.encode("utf-8"), write_to=pdf_path, dpi=900)
        except Exception as e:
            self.logger.warning(f"PDF conversion failed: {e}")
            pdf_path = None
        
        # Save EPS file (replacing AI file)
        eps_path = os.path.join(base_dir, f"{base_name}_vector.eps")
        try:
            # Convert SVG to EPS using cairosvg
            cairosvg.svg2ps(bytestring=svg_str.encode("utf-8"), write_to=eps_path, dpi=900)
        except Exception as e:
            self.logger.warning(f"EPS conversion failed: {e}")
            eps_path = None
        
        self.logger.info(f"Multi-color RGBA vector trace completed for {file_path} with {upscale_factor}x upscaling")
        
        return {
            'status': 'success',
            'output_paths': {
                'svg': svg_path,
                'pdf': pdf_path if pdf_path else None,
                'eps': eps_path if eps_path else None
            },
            'preview_paths': {
                'svg': svg_path,
                'pdf': pdf_path if pdf_path else None
            },
            'processing_time': 0,
            'organized_structure': {},
            'total_paths': 1,
            'quality_level': 'vtracer-multi-color-rgba-direct',
            'algorithm': 'rgba-pixel-direct-processing',
            'upscale_factor': upscale_factor,
            'processing_details': {
                'library': 'vtracer',
                'mode': 'multi-color-rgba',
                'colormode': 'color',
                'hierarchical': 'stacked',
                'color_precision': 6,
                'upscaling': f'{upscale_factor}x',
                'preprocessing': 'Direct RGBA pixel processing',
                'speckle_filtering': 0,
                'corner_threshold': 15,
                'path_precision': 5
            }
        }

        """Get task complexity for optimization"""
        return {'score': 1, 'priority': 1}  # Simplified for speed
    
    def calculate_optimal_workers_for_task(self, task_name: str, total_available_workers: int) -> int:
        """Calculate optimal workers for task"""
        return min(4, total_available_workers)  # Simplified for speed
    
    def create_subtasks(self, task_name: str, file_path: str, options: dict) -> list:
        """Create subtasks for parallel processing"""
        return []  # Simplified for speed
    
    def execute_task_with_subtasks(self, task_name: str, file_path: str, options: dict, available_workers: int) -> dict:
        """Execute task with subtasks"""
        return {'status': 'completed'}  # Simplified for speed
    
    def combine_subtask_results(self, task_name: str, subtask_results: dict, options: dict) -> dict:
        """Combine subtask results"""
        return subtask_results  # Simplified for speed

